[experiment]
exp_name_suffix = string()                                  # Suffix to append to `exp_name`
tags = string_list()                                        # optional set of tags
seed = integer(default=-1)                                  # random seed
debug = boolean(default=0)                                  # If True, debugging
train = boolean(default=0)                                  # If True, train model
test = boolean(default=0)                                   # If True, test model
use_comet_logger = boolean(default=0)                       # If True, use Comet ML Logger

[debug]             # Model debugging arguments
    [[general]]
    use_influence_function = boolean(default=0)             # If True, use influence functions to debug harmful predictions

[data]              # Data arguments
    [[general]]         # General shared arguments
    dsets = string_list(default=list("sickkids"))           # Dataset/s to load in training/validation
    full_seq = boolean(default=0)                           # If True, using full video sequence in training/inference

    [[sickkids]]        # SickKids-specific arguments
    exclude_filename_json = string()                        # If provided, list of filenames to exclude from SickKids train/val/test

    [[transforms]]      # Image pre-processing arguments
    standardize_images = boolean(default=0)                 # If True, standardizes images with training set pre-computed mean/std

    [[training]]        # Training-related arguments
    include_unlabeled = boolean(default=0)                  # If True, adding unlabeled images during training
    train_test_split = float(min=0, max=1, default=0.75)    # Prop. of total data to leave for training & validation, rest for testing
    train_val_split = float(min=0, max=1, default=0.75)     # Prop. of data after removing test for training, rest for validation
    cross_val_folds = integer(min=1, default=1)             # If >1, perform K-Fold cross-validation
    force_train_ids = string_list()                         # List of patient IDs to place into training set

    [[augment]]         # Augmentations during training
    augment_training = boolean(default=0)                   # If True, adding augmentations during training
    crop_scale = float(min=0.01, max=1.0, default=0.3)      # Lower bound on proportion of area cropped relative to the full image.

    [[dataloader]]      # Dataloader-related arguments
    batch_size = integer(min=1, default=16)                 # Batch size
    shuffle = boolean(default=0)                            # If True, shuffling data
    num_workers = integer(min=1, default=4)                 # Number of CPU workers
    pin_memory = boolean(default=0)                         # If True, pins tensors to GPU

    [[segmentation]]    # Segmentation arguments for GradCAM loss
    load_seg_mask = boolean(default=0)                      # If True, load segmentation masks
    include_liver_seg = boolean(default=0)                  # If True, combining liver masks with other masks
    ensure_seg_mask = boolean(default=0)                    # If True, filter training set for only samples with segmentation masks

[model]
    [[training]]            # Training arguments
    checkpoint = boolean(default=1)                         # If True, performing checkpointing
    precision = option("16", "bf16", "16-mixed", "bf16-mixed", "32", default="16-mixed")    # Model precision
    stop_epoch = integer(min=1, default=10)                # Number of epochs

    [[pretrained]]          # Pre-trained model arguments
    freeze_weights = boolean(default=0)                     # If True, weights stay frozen

    [[optim]]               # Optimization parameters
    optimizer = option("sgd", "adamw", default="adamw")     # Optimizer of choice
    lr = float(min=0.000001, default=0.001)                 # Learning rate
    weight_decay = float(min=0, default=0.001)              # Weight decay
    momentum = float(min=0, default=0.9)                    # SGD momentum
    grad_clip_norm = float(min=0, default=1.0)              # Gradient clipping norm
    swa = boolean(default=1)                                # If True, performing Stochastic Weight Averaging
    use_grokfast = boolean(default=0)                       # If True, use Grokfast-EMA
    accum_batches = integer(min=1, default=1)               # Number of batches to accumulate gradient over to increase eeffective batch size

    [[gradcam_loss]]                # Loss arguments
    use_gradcam_loss = boolean(default=0)                   # If True, adding auxiliary GradCAM loss
    use_orig_implement = boolean(default=0)                 # If True, using original GradCAM loss implementation
    gradcam_loss_weight = float(min=0., default=1.)         # Weight of GradCAM loss when added to cross-entropy loss
    use_all_class_gradcam_loss = boolean(default=1)         # If True, penalizing ALL classes for having gradients OUTSIDE the positive class mask
    add_neg_class_gradcam_loss = boolean(default=0)         # If True, penalizing NEGATIVE classes for having gradients IN the positive class mask

    [[efficientnet]]        # EfficientNet model arguments
    effnet_name = string(min=1, default="efficientnet-b0")  # Name of EfficientNet backbone

    [[lstm]]                # LSTM-specific arguments
    n_lstm_layers = integer(min=1, default=1)               # Number of LSTM layers
    hidden_dim = integer(default=512)                       # Hidden dimension size
    bidirectional = boolean(default=0)                      # If True, bidirectional LSTM

    [[misc]]                # Miscellaneous arguments
    torch_compile = boolean(default=0)                      # If True, using `torch.compile` on model
    multi_output = boolean(default=0)                       # If True, using multi-output supervised model

[ssl]               # Self-supervised pre-training specific arguments
self_supervised = true